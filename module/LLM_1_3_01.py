import re
import requests
import json
import time

# æ·»åŠ åœ°ç‚¹å˜é‡ï¼ˆåœ¨æ–‡ä»¶å¼€å¤´ï¼‰
CURRENT_PROVINCE = "å¹¿ä¸œ"  # åœ¨è¿™é‡Œè®¾ç½®çœä»½

# å¿ƒç†å¥åº·çƒ­çº¿æ•°æ®åº“
MENTAL_HEALTH_HOTLINES = {
    "å…¨å›½": {
        "é’å°‘å¹´æ³•å¾‹ä¸å¿ƒç†å’¨è¯¢çƒ­çº¿": "12355",
        "å…¨å›½é’å°‘å¹´å¿ƒç†å¥åº·ä¸“çº¿": "4000-100-525",
        "å…¨å›½å¿ƒç†æ´åŠ©çƒ­çº¿": "400-161-9995",
        "æœåŠ¡æ—¶é—´": "24å°æ—¶"
    },
    "åŒ—äº¬": {
        "åŒ—äº¬å¸‚å¿ƒç†æ´åŠ©çƒ­çº¿": "010-82951332",
        "åŒ—äº¬å¿ƒç†å±æœºå¹²é¢„ä¸­å¿ƒ": "010-62715275",
        "é’å°‘å¹´æ³•å¾‹ä¸å¿ƒç†å’¨è¯¢çƒ­çº¿": "12355",
        "å…¨å›½é’å°‘å¹´å¿ƒç†å¥åº·ä¸“çº¿": "4000-100-525",
        "æœåŠ¡æ—¶é—´": "24å°æ—¶"
    },
    "ä¸Šæµ·": {
        "ä¸Šæµ·å¸‚å¿ƒç†æ´åŠ©çƒ­çº¿": "021-12320-5",
        "ä¸Šæµ·é’å°‘å¹´å…¬å…±æœåŠ¡å¹³å°": "12355",
        "é’å°‘å¹´æ³•å¾‹ä¸å¿ƒç†å’¨è¯¢çƒ­çº¿": "12355",
        "å…¨å›½é’å°‘å¹´å¿ƒç†å¥åº·ä¸“çº¿": "4000-100-525",
        "æœåŠ¡æ—¶é—´": "24å°æ—¶"
    },
    "å¹¿ä¸œ": {
        "å¹¿ä¸œçœå¿ƒç†æ´åŠ©çƒ­çº¿": "020-81899120",
        "å¹¿å·å¸‚å¿ƒç†æ´åŠ©çƒ­çº¿": "020-81899120",
        "é’å°‘å¹´æ³•å¾‹ä¸å¿ƒç†å’¨è¯¢çƒ­çº¿": "12355",
        "å…¨å›½é’å°‘å¹´å¿ƒç†å¥åº·ä¸“çº¿": "4000-100-525",
        "æœåŠ¡æ—¶é—´": "24å°æ—¶"
    },
    "æ±Ÿè‹": {
        "æ±Ÿè‹çœå¿ƒç†æ´åŠ©çƒ­çº¿": "025-83712977",
        "å—äº¬å¸‚å¿ƒç†æ´åŠ©ä¸­å¿ƒ": "025-83712977",
        "é’å°‘å¹´æ³•å¾‹ä¸å¿ƒç†å’¨è¯¢çƒ­çº¿": "12355",
        "å…¨å›½é’å°‘å¹´å¿ƒç†å¥åº·ä¸“çº¿": "4000-100-525",
        "æœåŠ¡æ—¶é—´": "24å°æ—¶"
    },
    "æµ™æ±Ÿ": {
        "æµ™æ±Ÿçœå¿ƒç†æ´åŠ©çƒ­çº¿": "0571-85029595",
        "æ­å·å¸‚å¿ƒç†æ´åŠ©çƒ­çº¿": "0571-85029595",
        "é’å°‘å¹´æ³•å¾‹ä¸å¿ƒç†å’¨è¯¢çƒ­çº¿": "12355",
        "å…¨å›½é’å°‘å¹´å¿ƒç†å¥åº·ä¸“çº¿": "4000-100-525",
        "æœåŠ¡æ—¶é—´": "24å°æ—¶"
    },
    "å››å·": {
        "å››å·çœå¿ƒç†æ´åŠ©çƒ­çº¿": "028-87577510",
        "æˆéƒ½å¸‚å¿ƒç†æ´åŠ©çƒ­çº¿": "028-87528604",
        "é’å°‘å¹´æ³•å¾‹ä¸å¿ƒç†å’¨è¯¢çƒ­çº¿": "12355",
        "å…¨å›½é’å°‘å¹´å¿ƒç†å¥åº·ä¸“çº¿": "4000-100-525",
        "æœåŠ¡æ—¶é—´": "24å°æ—¶"
    },
    "æ¹–åŒ—": {
        "æ¹–åŒ—çœå¿ƒç†æ´åŠ©çƒ­çº¿": "027-85844666",
        "æ­¦æ±‰å¸‚å¿ƒç†åŒ»é™¢çƒ­çº¿": "027-85844666",
        "é’å°‘å¹´æ³•å¾‹ä¸å¿ƒç†å’¨è¯¢çƒ­çº¿": "12355",
        "å…¨å›½é’å°‘å¹´å¿ƒç†å¥åº·ä¸“çº¿": "4000-100-525",
        "æœåŠ¡æ—¶é—´": "24å°æ—¶"
    },
    "é™•è¥¿": {
        "é™•è¥¿çœå¿ƒç†æ´åŠ©çƒ­çº¿": "029-63616911",
        "è¥¿å®‰å¸‚å¿ƒç†æ´åŠ©çƒ­çº¿": "029-63616911",
        "é’å°‘å¹´æ³•å¾‹ä¸å¿ƒç†å’¨è¯¢çƒ­çº¿": "12355",
        "å…¨å›½é’å°‘å¹´å¿ƒç†å¥åº·ä¸“çº¿": "4000-100-525",
        "æœåŠ¡æ—¶é—´": "24å°æ—¶"
    },
    "default": {
        "é’å°‘å¹´æ³•å¾‹ä¸å¿ƒç†å’¨è¯¢çƒ­çº¿": "12355",
        "å…¨å›½é’å°‘å¹´å¿ƒç†å¥åº·ä¸“çº¿": "4000-100-525",
        "å…¨å›½å¿ƒç†æ´åŠ©çƒ­çº¿": "400-161-9995",
        "æœåŠ¡æ—¶é—´": "24å°æ—¶"
    }
}

# Hugging Face Token - è¯·æ›¿æ¢ä¸ºæ‚¨çš„çœŸå®token
# HF_TOKEN = "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"
HF_TOKEN = "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"

headers = {"Authorization": f"Bearer {HF_TOKEN}"}

# æƒ…æ„Ÿåˆ†ç±» - ä½¿ç”¨æ›´å‡†ç¡®çš„æƒ…æ„Ÿåˆ†ææ¨¡å‹
EMOTION_API_URL = "https://api-inference.huggingface.co/models/bhadresh-savani/bert-base-uncased-emotion"

# æƒ…æ„Ÿå¼ºåº¦åˆ†æ - æ¢ç”¨æ›´å‡†ç¡®çš„æƒ…æ„Ÿå¼ºåº¦åˆ†ææ¨¡å‹
INTENSITY_API_URL = "https://api-inference.huggingface.co/models/cardiffnlp/twitter-roberta-base-sentiment-latest"

# å®‰æŠšAPI - ä½¿ç”¨æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼ˆç¡®ä¿å¯ç”¨çš„æ¨¡å‹ï¼‰
COMFORT_API_URL = "https://api-inference.huggingface.co/models/microsoft/DialoGPT-medium"

# å®‰å…¨è§„åˆ™è¡¨æ ¼ - æ ¹æ®æä¾›çš„è¡¨æ ¼å®šä¹‰
SAFETY_RULES = {
    "é«˜å…´": {"low": "normal", "medium": "normal", "high": "normal"},
    "æ‚²ä¼¤": {"low": "normal", "medium": "normal", "high": "caution"},
    "æ„¤æ€’": {"low": "normal", "medium": "caution", "high": "critical"},
    "ææƒ§": {"low": "normal", "medium": "caution", "high": "critical"},
    "æƒŠè®¶": {"low": "normal", "medium": "normal", "high": "normal"},
    "åŒæ¶": {"low": "normal", "medium": "caution", "high": "caution"}
}

# ç´§æ€¥å…³é”®è¯åˆ—è¡¨ - éœ€è¦æ ¹æ®å®é™…æƒ…å†µæ‰©å±•
CRITICAL_KEYWORDS = [
    "è‡ªæ€", "è‡ªæ®‹", "æ€äºº", "ä¼¤å®³", "æ­»äº†ç®—äº†", "ä¸æƒ³æ´»äº†", "æ´»å¤Ÿäº†",
    "è·³æ¥¼", "è·³æ²³", "ä¸ŠåŠ", "å‰²è…•", "å®‰çœ è¯", "åŒå½’äºå°½", "æŠ¥å¤ç¤¾ä¼š"
]

# Ekman 6æƒ…ç»ªæ˜ å°„è¡¨ - é’ˆå¯¹æ–°æ¨¡å‹ä¼˜åŒ–
EKMAN_MAPPING = {
    # é«˜å…´/å¿«ä¹
    "joy": "é«˜å…´", "happy": "é«˜å…´", "happiness": "é«˜å…´", "love": "é«˜å…´",
    "optimism": "é«˜å…´", "excitement": "é«˜å…´", "amusement": "é«˜å…´",

    # æ‚²ä¼¤
    "sadness": "æ‚²ä¼¤", "sad": "æ‚²ä¼¤", "grief": "æ‚²ä¼¤", "disappointment": "æ‚²ä¼¤",
    "remorse": "æ‚²ä¼¤", "sorrow": "æ‚²ä¼¤",

    # æ„¤æ€’
    "anger": "æ„¤æ€’", "angry": "æ„¤æ€’", "rage": "æ„¤æ€’", "fury": "æ„¤æ€’",
    "annoyance": "æ„¤æ€’", "irritation": "æ„¤æ€’",

    # ææƒ§
    "fear": "ææƒ§", "scared": "ææƒ§", "terror": "ææƒ§", "anxiety": "ææƒ§",
    "nervousness": "ææƒ§", "panic": "ææƒ§",

    # æƒŠè®¶
    "surprise": "æƒŠè®¶", "surprised": "æƒŠè®¶", "amazement": "æƒŠè®¶",
    "astonishment": "æƒŠè®¶", "shock": "æƒŠè®¶",

    # åŒæ¶
    "disgust": "åŒæ¶", "disgusted": "åŒæ¶", "revulsion": "åŒæ¶",
    "contempt": "åŒæ¶", "hatred": "åŒæ¶"
}


def set_current_province(province):
    """è®¾ç½®å½“å‰åœ°ç‚¹"""
    global CURRENT_PROVINCE
    CURRENT_PROVINCE = province
    print(f"ğŸ“ å½“å‰åœ°ç‚¹å·²è®¾ç½®ä¸º: {province}")


def get_mental_health_hotlines():
    """æ ¹æ®å½“å‰åœ°ç‚¹è¿”å›å¿ƒç†å¥åº·çƒ­çº¿"""
    global CURRENT_PROVINCE

    # è·å–å½“å‰åœ°ç‚¹çš„çƒ­çº¿ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤
    if CURRENT_PROVINCE in MENTAL_HEALTH_HOTLINES:
        hotlines = MENTAL_HEALTH_HOTLINES[CURRENT_PROVINCE]
    else:
        hotlines = MENTAL_HEALTH_HOTLINES["default"]
        print(f"âš ï¸  æœªæ‰¾åˆ° {CURRENT_PROVINCE} çš„çƒ­çº¿ä¿¡æ¯ï¼Œä½¿ç”¨å…¨å›½é»˜è®¤çƒ­çº¿")

    # ç¡®ä¿åŒ…å«ä¸¤ä¸ªå¿…é€‰çƒ­çº¿
    required_hotlines = {
        "é’å°‘å¹´æ³•å¾‹ä¸å¿ƒç†å’¨è¯¢çƒ­çº¿": "12355",
        "å…¨å›½é’å°‘å¹´å¿ƒç†å¥åº·ä¸“çº¿": "4000-100-525"
    }

    # åˆå¹¶çƒ­çº¿ï¼Œç¡®ä¿å¿…é€‰çƒ­çº¿å­˜åœ¨
    merged_hotlines = {**hotlines, **required_hotlines}

    return merged_hotlines


def format_hotlines_for_display(hotlines):
    """æ ¼å¼åŒ–çƒ­çº¿ä¿¡æ¯ç”¨äºæ˜¾ç¤º"""
    display_lines = []

    # å…ˆæ·»åŠ ä¸¤ä¸ªå¿…é€‰çƒ­çº¿
    display_lines.append(f"ğŸ“ é’å°‘å¹´æ³•å¾‹ä¸å¿ƒç†å’¨è¯¢çƒ­çº¿: {hotlines['é’å°‘å¹´æ³•å¾‹ä¸å¿ƒç†å’¨è¯¢çƒ­çº¿']}")
    display_lines.append(f"ğŸ“ å…¨å›½é’å°‘å¹´å¿ƒç†å¥åº·ä¸“çº¿: {hotlines['å…¨å›½é’å°‘å¹´å¿ƒç†å¥åº·ä¸“çº¿']}")

    # æ·»åŠ å…¶ä»–çƒ­çº¿ï¼ˆæ’é™¤é‡å¤å’Œå¿…é€‰çš„ï¼‰
    added_count = 2
    for name, number in hotlines.items():
        if name not in ["é’å°‘å¹´æ³•å¾‹ä¸å¿ƒç†å’¨è¯¢çƒ­çº¿", "å…¨å›½é’å°‘å¹´å¿ƒç†å¥åº·ä¸“çº¿", "æœåŠ¡æ—¶é—´"] and added_count < 5:
            display_lines.append(f"ğŸ“ {name}: {number}")
            added_count += 1

    # æ·»åŠ æœåŠ¡æ—¶é—´
    if "æœåŠ¡æ—¶é—´" in hotlines:
        display_lines.append(f"â° æœåŠ¡æ—¶é—´: {hotlines['æœåŠ¡æ—¶é—´']}")

    return display_lines


def call_huggingface_api(api_url, text):
    """è°ƒç”¨Hugging Face APIçš„é€šç”¨å‡½æ•°ï¼Œåªè°ƒç”¨ä¸€æ¬¡"""
    try:
        payload = {"inputs": text}
        print(f"è°ƒç”¨API: {api_url.split('/')[-1]}")

        response = requests.post(api_url, headers=headers, json=payload, timeout=30)

        if response.status_code == 200:
            result = response.json()
            print(f"APIè°ƒç”¨æˆåŠŸ")
            return result
        elif response.status_code == 503:
            print("æ¨¡å‹æ­£åœ¨åŠ è½½ï¼Œæ— æ³•ç«‹å³å“åº”")
            return {"error": "model_loading"}
        elif response.status_code == 404:
            print(f"æ¨¡å‹ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {api_url}")
            return {"error": "model_not_found"}
        else:
            print(f"APIè°ƒç”¨å¤±è´¥: {response.status_code}")
            print(f"é”™è¯¯ä¿¡æ¯: {response.text[:200]}...")
            return {"error": f"http_error_{response.status_code}"}

    except requests.exceptions.Timeout:
        print(f"APIè°ƒç”¨è¶…æ—¶")
        return {"error": "timeout"}

    except Exception as e:
        print(f"APIè°ƒç”¨å¼‚å¸¸: {e}")
        return {"error": f"exception_{str(e)}"}


def extract_keywords(text):
    """æå–å…³é”®è¯"""
    # ç®€å•çš„å…³é”®è¯æå–ï¼Œå¯ä»¥æ ¹æ®éœ€æ±‚æ‰©å±•
    keywords = re.findall(r'[\u4e00-\u9fff]{2,}', text)
    # å»é™¤å¸¸è§åœç”¨è¯
    stop_words = ['ä¸ºä»€ä¹ˆ', 'å¤§å®¶', 'æˆ‘çš„', 'ä½ çš„', 'è¿™ä¸ª', 'é‚£ä¸ª', 'å°±æ˜¯', 'å¯ä»¥', 'åº”è¯¥']
    keywords = [kw for kw in keywords if kw not in stop_words and len(kw) > 1]

    return keywords[:10]  # è¿”å›å‰10ä¸ªå…³é”®è¯









def get_fallback_comfort_message(analysis_data):
    """å›é€€å®‰æŠšæ¶ˆæ¯"""
    emotion = analysis_data['mark_a']['primary_emotion']
    intensity = analysis_data['mark_b']['intensity']

    comfort_messages = {
        "æ‚²ä¼¤": [
            "æˆ‘èƒ½æ„Ÿå—åˆ°æ‚¨ç°åœ¨çš„ç—›è‹¦ï¼Œè¯·è®°ä½æ‚¨å¹¶ä¸å­¤å•ã€‚æ‚²ä¼¤æ˜¯æ­£å¸¸çš„æƒ…ç»ªï¼Œç»™è‡ªå·±ä¸€äº›æ—¶é—´å’Œç©ºé—´ã€‚",
            "æˆ‘ç†è§£æ‚¨çš„å¿ƒæƒ…ï¼Œæ‚²ä¼¤æ—¶éœ€è¦è¢«ç†è§£å’Œé™ªä¼´ã€‚è¯·ç›¸ä¿¡ï¼Œè‰°éš¾çš„æ—¶åˆ»ä¼šè¿‡å»çš„ã€‚",
            "æ‚¨çš„æ„Ÿå—å¾ˆé‡è¦ï¼Œæ‚²ä¼¤æ˜¯äººä¹‹å¸¸æƒ…ã€‚æˆ‘ä¼šåœ¨è¿™é‡Œé™ªä¼´æ‚¨ï¼Œæ”¯æŒæ‚¨åº¦è¿‡è¿™ä¸ªæ—¶åˆ»ã€‚"
        ],
        "æ„¤æ€’": [
            "æˆ‘ç†è§£æ‚¨ç°åœ¨å¾ˆç”Ÿæ°”ï¼Œè®©æˆ‘ä»¬å…ˆæ·±å‘¼å¸å‡ æ¬¡ã€‚å¼ºçƒˆçš„æƒ…ç»ªéœ€è¦è¢«çœ‹è§å’Œç†è§£ã€‚",
            "æ„¤æ€’æ˜¯æ­£å¸¸çš„æƒ…ç»ªååº”ï¼Œæˆ‘ç†è§£æ‚¨çš„æ„Ÿå—ã€‚è®©æˆ‘ä»¬ä¸€èµ·å†·é™ä¸‹æ¥ï¼Œæ‰¾åˆ°æ›´å¥½çš„è§£å†³æ–¹æ³•ã€‚",
            "æˆ‘èƒ½æ„Ÿå—åˆ°æ‚¨çš„æ„¤æ€’ï¼Œè¿™ç§æƒ…ç»ªå¾ˆå¼ºçƒˆã€‚è¯·ç»™è‡ªå·±ä¸€ç‚¹ç©ºé—´ï¼Œæˆ‘ä¼šåœ¨è¿™é‡Œæ”¯æŒæ‚¨ã€‚"
        ],
        "ææƒ§": [
            "å®³æ€•æ˜¯æ­£å¸¸çš„ååº”ï¼Œæ‚¨ç°åœ¨å¾ˆå®‰å…¨ã€‚è®©æˆ‘ä»¬ä¸€èµ·é¢å¯¹è¿™äº›ææƒ§ã€‚",
            "æˆ‘ç†è§£æ‚¨çš„ææƒ§ï¼Œè¿™ç§æ„Ÿè§‰å¾ˆçœŸå®ã€‚è¯·è®°ä½ï¼Œæ‚¨ä¸æ˜¯ä¸€ä¸ªäººåœ¨é¢å¯¹è¿™äº›ã€‚",
            "ææƒ§æ¥ä¸´æ—¶ç¡®å®è®©äººä¸å®‰ï¼Œä½†è¯·ç›¸ä¿¡æ‚¨æœ‰èƒ½åŠ›åº”å¯¹ã€‚æˆ‘ä¼šåœ¨è¿™é‡Œé™ªä¼´æ‚¨ã€‚"
        ],
        "åŒæ¶": [
            "æˆ‘ç†è§£æ‚¨çš„åæ„Ÿæƒ…ç»ªï¼Œæœ‰äº›æƒ…å†µç¡®å®è®©äººéš¾ä»¥æ¥å—ã€‚æˆ‘ä»¬å¯ä»¥ä¸€èµ·æ‰¾åˆ°æ›´å¥½çš„åº”å¯¹æ–¹å¼ã€‚",
            "åŒæ¶çš„æ„Ÿè§‰å¾ˆä¸èˆ’æœï¼Œæˆ‘ç†è§£æ‚¨çš„æ„Ÿå—ã€‚è®©æˆ‘ä»¬è¯•ç€ä»ä¸åŒè§’åº¦çœ‹å¾…è¿™ä¸ªé—®é¢˜ã€‚",
            "è¿™ç§åæ„Ÿæƒ…ç»ªå¾ˆæ­£å¸¸ï¼Œé‡è¦çš„æ˜¯æˆ‘ä»¬å¦‚ä½•åº”å¯¹ã€‚æˆ‘ä¼šæ”¯æŒæ‚¨æ‰¾åˆ°è§£å†³çš„æ–¹æ³•ã€‚"
        ],
        "é«˜å…´": [
            "å¾ˆé«˜å…´çœ‹åˆ°æ‚¨æœ‰ç§¯æçš„æƒ…ç»ªï¼è¯·äº«å—è¿™ä»½ç¾å¥½ï¼ŒåŒæ—¶ä¹Ÿè¦è®°å¾—ç…§é¡¾å¥½è‡ªå·±çš„å„ç§æƒ…ç»ªã€‚",
            "ç§¯æçš„æƒ…ç»ªå¾ˆå®è´µï¼Œæˆ‘ä¸ºæ‚¨æ„Ÿåˆ°é«˜å…´ã€‚è¯·ç»§ç»­ä¿æŒè¿™ç§çŠ¶æ€ã€‚",
            "çœ‹åˆ°æ‚¨å¿ƒæƒ…ä¸é”™ï¼Œè¿™å¾ˆæ£’ï¼æƒ…ç»ªæœ‰èµ·ä¼æ˜¯æ­£å¸¸çš„ï¼Œäº«å—å½“ä¸‹çš„ç¾å¥½æ—¶åˆ»ã€‚"
        ],
        "æƒŠè®¶": [
            "æ„å¤–çš„æƒ…å†µç¡®å®ä¼šè®©äººæ„Ÿåˆ°æƒŠè®¶ï¼Œæˆ‘ç†è§£æ‚¨çš„æ„Ÿå—ã€‚è®©æˆ‘ä»¬ä¸€èµ·ç†æ¸…æ€è·¯ã€‚",
            "æƒŠè®¶çš„æƒ…ç»ªå¾ˆè‡ªç„¶ï¼Œé¢å¯¹çªå‘æƒ…å†µæ—¶æˆ‘ä»¬éƒ½ä¼šæœ‰è¿™æ ·çš„ååº”ã€‚",
            "æˆ‘ç†è§£æ‚¨çš„æƒŠè®¶ï¼Œè¿™ç§æƒ…å†µç¡®å®å‡ºä¹æ„æ–™ã€‚è®©æˆ‘ä»¬æ…¢æ…¢å¤„ç†ã€‚"
        ]
    }

    messages = comfort_messages.get(emotion, comfort_messages['é«˜å…´'])  # é»˜è®¤ä½¿ç”¨é«˜å…´
    # æ ¹æ®å¼ºåº¦é€‰æ‹©ä¸åŒçš„æ¶ˆæ¯
    message_index = min(int(intensity * len(messages)), len(messages) - 1)
    message = messages[message_index]

    return {
        "comfort_message": message,
        "emergency_contact_initiated": True,
        "source": "fallback_comfort"
    }


def ekman_emotion_classification(text):
    """
    æƒ…æ„Ÿåˆ†ç±» - ä½¿ç”¨æ›´å‡†ç¡®çš„æƒ…æ„Ÿåˆ†ææ¨¡å‹ï¼Œåªè°ƒç”¨ä¸€æ¬¡
    """
    print("=== å¼€å§‹æƒ…æ„Ÿåˆ†ç±» ===")

    api_result = call_huggingface_api(EMOTION_API_URL, text)

    if api_result is None or "error" in api_result:
        print("æƒ…æ„Ÿåˆ†æAPIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ")
        return get_fallback_emotion(text)

    return process_emotion_result(api_result, text)


def process_emotion_result(api_result, text):
    """å¤„ç†æƒ…æ„Ÿåˆ†ç±»ç»“æœ"""
    try:
        processed_results = []
        primary_emotion = "é«˜å…´"  # é»˜è®¤æ”¹ä¸ºé«˜å…´
        max_score = 0

        # å¤„ç†APIå“åº”æ ¼å¼
        if isinstance(api_result, list) and len(api_result) > 0:
            emotions_data = api_result[0]
        else:
            emotions_data = api_result

        # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
        if not isinstance(emotions_data, list):
            print(f"APIè¿”å›æ ¼å¼å¼‚å¸¸: {type(emotions_data)}ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ")
            return get_fallback_emotion(text)

        for item in emotions_data:
            if isinstance(item, dict):
                label = item.get('label', '')
                score = item.get('score', 0)

                # æ˜ å°„åˆ°Ekmanæƒ…ç»ª
                emotion_label = EKMAN_MAPPING.get(label, None)
                if emotion_label is None:
                    emotion_label = EKMAN_MAPPING.get(label.lower(), None)

                # å¦‚æœæ˜ å°„æˆåŠŸï¼Œæ·»åŠ åˆ°ç»“æœä¸­
                if emotion_label:
                    processed_results.append({
                        'original_label': label,
                        'emotion_label': emotion_label,
                        'score': score
                    })

                    # æ‰¾åˆ°ä¸»è¦æƒ…ç»ª
                    if score > max_score:
                        max_score = score
                        primary_emotion = emotion_label

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæƒ…ç»ªï¼Œä½¿ç”¨å›é€€
        if not processed_results:
            return get_fallback_emotion(text)

        mark_a = {
            'primary_emotion': primary_emotion,
            'confidence': max_score,
            'all_emotions': processed_results
        }

        return mark_a

    except Exception as e:
        print(f"å¤„ç†æƒ…æ„Ÿç»“æœæ—¶å‡ºé”™: {e}")
        return get_fallback_emotion(text)


def emotion_intensity_analysis(text):
    """
    æƒ…æ„Ÿå¼ºåº¦åˆ†æ - ä½¿ç”¨æ›´å‡†ç¡®çš„æƒ…æ„Ÿåˆ†ææ¨¡å‹
    """
    print("=== å¼€å§‹æƒ…æ„Ÿå¼ºåº¦åˆ†æ ===")
    api_result = call_huggingface_api(INTENSITY_API_URL, text)

    if api_result is None or "error" in api_result:
        print("å¼ºåº¦åˆ†æAPIå¤±è´¥ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ")
        return get_fallback_intensity(text)

    return process_intensity_result(api_result, text)


def process_intensity_result(api_result, text):
    """å¤„ç†å¼ºåº¦åˆ†æç»“æœ"""
    try:
        if isinstance(api_result, list) and len(api_result) > 0:
            intensity_data = api_result[0]

            # æ–°æ¨¡å‹è¿”å›æ­£é¢ã€è´Ÿé¢ã€ä¸­æ€§ä¸‰ç§æƒ…æ„Ÿ
            positive_score = 0
            negative_score = 0
            neutral_score = 0

            for item in intensity_data:
                if isinstance(item, dict):
                    label = item.get('label', '')
                    score = item.get('score', 0)

                    if 'positive' in label.lower() or 'pos' in label.lower():
                        positive_score = score
                    elif 'negative' in label.lower() or 'neg' in label.lower():
                        negative_score = score
                    elif 'neutral' in label.lower():
                        neutral_score = score

            # æ–°çš„å¼ºåº¦è®¡ç®—é€»è¾‘ï¼šåŸºäºæƒ…æ„Ÿææ€§å’Œç½®ä¿¡åº¦
            if positive_score > negative_score:
                # æ­£é¢æƒ…æ„Ÿï¼Œå¼ºåº¦åŸºäºæ­£é¢åˆ†æ•°
                base_intensity = positive_score
            else:
                # è´Ÿé¢æƒ…æ„Ÿï¼Œå¼ºåº¦åŸºäºè´Ÿé¢åˆ†æ•°
                base_intensity = negative_score

            # ç¡®ä¿å¼ºåº¦åœ¨åˆç†èŒƒå›´å†…
            intensity = min(max(base_intensity, 0), 1.0)

            # åŸºäºæ–‡æœ¬ç‰¹å¾å¾®è°ƒ
            adjusted_intensity = adjust_intensity_with_features(intensity, text)

            mark_b = {
                'intensity': adjusted_intensity,
                'level': get_intensity_level(adjusted_intensity),
                'raw_intensity': intensity,
                'positive_score': positive_score,
                'negative_score': negative_score,
                'neutral_score': neutral_score
            }

            return mark_b
        else:
            return get_fallback_intensity(text)
    except Exception as e:
        print(f"å¤„ç†å¼ºåº¦ç»“æœæ—¶å‡ºé”™: {e}")
        return get_fallback_intensity(text)


def adjust_intensity_with_features(base_intensity, text):
    """åŸºäºæ–‡æœ¬ç‰¹å¾è°ƒæ•´å¼ºåº¦å€¼ - æ›´ä¿å®ˆçš„è°ƒæ•´"""
    adjusted_intensity = base_intensity

    # 1. æ„Ÿå¹å·å¢å¼ºï¼ˆæ›´ä¿å®ˆï¼‰
    exclamation_count = text.count('!') + text.count('ï¼')
    if exclamation_count > 0:
        adjusted_intensity += min(exclamation_count * 0.05, 0.15)

    # 2. å¼ºåº¦å‰¯è¯å¢å¼ºï¼ˆæ›´ä¿å®ˆï¼‰
    intensity_adverbs = ['éå¸¸', 'å¾ˆ', 'ç‰¹åˆ«', 'æå…¶', 'è¶…çº§', 'ååˆ†', 'å¤ª', 'çœŸçš„', 'è¶…çº§', 'æåº¦']
    adverb_count = sum(text.count(adverb) for adverb in intensity_adverbs)
    if adverb_count > 0:
        adjusted_intensity += min(adverb_count * 0.04, 0.12)

    # 3. é‡å¤è¯å¢å¼º
    words = re.findall(r'[\u4e00-\u9fff]+', text)
    for word in words:
        if len(word) > 1 and text.count(word) > 1:
            adjusted_intensity += 0.03
            break

    # 4. æƒ…æ„Ÿè¯å¢å¼ºï¼ˆæ›´ä¿å®ˆï¼‰
    emotional_words = ['ç—›è‹¦', 'ç»æœ›', 'å´©æºƒ', 'ç–¯ç‹‚', 'å¹¸ç¦', 'å¿«ä¹', 'å…´å¥‹', 'ææƒ§']
    emotional_count = sum(text.count(word) for word in emotional_words)
    if emotional_count > 0:
        adjusted_intensity += min(emotional_count * 0.03, 0.1)

    return min(max(adjusted_intensity, 0), 1.0)


def get_fallback_emotion(text):
    """æƒ…ç»ªåˆ†ç±»å›é€€æ–¹æ¡ˆ - åªè¿”å›Ekman6ç§æƒ…æ„Ÿ"""
    print("ä½¿ç”¨å›é€€æ–¹æ¡ˆè¿›è¡Œæƒ…æ„Ÿåˆ†æ")
    emotion_keywords = {
        'é«˜å…´': ['å¼€å¿ƒ', 'å¿«ä¹', 'é«˜å…´', 'å¹¸ç¦', 'æ»¡æ„', 'å…´å¥‹', 'æ„‰å¿«', 'å–œæ‚¦', 'æ£’', 'å¥½', 'å–œæ¬¢', 'çˆ±', 'å“ˆå“ˆ',
                 'å‘µå‘µ'],
        'æ‚²ä¼¤': ['éš¾è¿‡', 'æ‚²ä¼¤', 'ä¼¤å¿ƒ', 'ç»æœ›', 'ç—›è‹¦', 'éƒé—·', 'æ²®ä¸§', 'æ‚²å“€', 'å“­', 'æ³ª', 'å¤±æœ›', 'éš¾å—'],
        'æ„¤æ€’': ['ç”Ÿæ°”', 'æ„¤æ€’', 'æ°”æ„¤', 'æ¼ç«', 'è®¨åŒ', 'æ¨', 'æš´èº', 'æ€¨æ¨', 'æ€’', 'çƒ¦', 'æ„¤æ€’', 'æ°”æ­»'],
        'ææƒ§': ['å®³æ€•', 'ææƒ§', 'ç´§å¼ ', 'ç„¦è™‘', 'æ‹…å¿ƒ', 'ææ…Œ', 'æƒŠæ…Œ', 'æ€•', 'å“', 'ææƒ§', 'ä¸å®‰'],
        'æƒŠè®¶': ['æƒŠè®¶', 'æƒŠå¥‡', 'åƒæƒŠ', 'æ„å¤–', 'éœ‡æƒŠ', 'å“‡', 'å¤©å•Š', 'æ²¡æƒ³åˆ°', 'å±…ç„¶', 'ç«Ÿç„¶'],
        'åŒæ¶': ['åŒæ¶', 'æ¶å¿ƒ', 'åæ„Ÿ', 'å«Œå¼ƒ', 'æ†æ¶', 'å', 'å‘•', 'è®¨åŒ', 'çƒ¦äºº', 'å—ä¸äº†']
    }

    emotion_scores = {}

    for emotion, keywords in emotion_keywords.items():
        score = 0
        for keyword in keywords:
            if keyword in text:
                score += 1
        if score > 0:
            emotion_scores[emotion] = score

    if emotion_scores:
        primary_emotion = max(emotion_scores, key=emotion_scores.get)
        confidence = min(emotion_scores[primary_emotion] * 0.2, 0.8)
    else:
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å…³é”®è¯ï¼Œé»˜è®¤è¿”å›é«˜å…´ï¼ˆè€Œä¸æ˜¯ä¸­æ€§ï¼‰
        primary_emotion = "é«˜å…´"
        confidence = 0.3

    return {
        'primary_emotion': primary_emotion,
        'confidence': confidence,
        'all_emotions': [{'original_label': 'fallback', 'emotion_label': primary_emotion, 'score': confidence}]
    }


def get_fallback_intensity(text):
    """å¼ºåº¦åˆ†æå›é€€æ–¹æ¡ˆ - æ›´ä¿å®ˆçš„å¼ºåº¦è®¡ç®—"""
    print("ä½¿ç”¨å›é€€æ–¹æ¡ˆè¿›è¡Œå¼ºåº¦åˆ†æ")
    intensity_factors = []

    # 1. æ–‡æœ¬é•¿åº¦å› ç´ ï¼ˆæ›´ä¿å®ˆï¼‰
    length_factor = min(len(text) / 100, 1.0)  # è°ƒæ•´ä¸º100å­—ç¬¦
    intensity_factors.append(length_factor * 0.15)

    # 2. æ„Ÿå¹å·æ•°é‡ï¼ˆæ›´ä¿å®ˆï¼‰
    exclamation_count = text.count('!') + text.count('ï¼')
    exclamation_factor = min(exclamation_count / 5, 1.0)  # è°ƒæ•´ä¸º5ä¸ªæ„Ÿå¹å·
    intensity_factors.append(exclamation_factor * 0.2)

    # 3. å¼ºåº¦å‰¯è¯ï¼ˆæ›´ä¿å®ˆï¼‰
    intensity_adverbs = ['éå¸¸', 'å¾ˆ', 'ç‰¹åˆ«', 'æå…¶', 'è¶…çº§', 'ååˆ†', 'å¤ª', 'çœŸçš„', 'è¶…çº§']
    adverb_count = sum(text.count(adverb) for adverb in intensity_adverbs)
    adverb_factor = min(adverb_count / 4, 1.0)  # è°ƒæ•´ä¸º4ä¸ªå‰¯è¯
    intensity_factors.append(adverb_factor * 0.3)

    # 4. æƒ…æ„Ÿè¯å¼ºåº¦ï¼ˆæ›´ä¿å®ˆï¼‰
    strong_emotional_words = ['ç—›è‹¦', 'ç»æœ›', 'å´©æºƒ', 'ç–¯ç‹‚', 'å¹¸ç¦', 'å¿«ä¹', 'å…´å¥‹', 'ææƒ§']
    strong_word_count = sum(text.count(word) for word in strong_emotional_words)
    strong_word_factor = min(strong_word_count / 3, 1.0)  # è°ƒæ•´ä¸º3ä¸ªæƒ…æ„Ÿè¯
    intensity_factors.append(strong_word_factor * 0.35)

    total_intensity = sum(intensity_factors)

    return {
        'intensity': min(total_intensity, 1.0),
        'level': get_intensity_level(total_intensity),
        'raw_intensity': total_intensity
    }


def get_intensity_level(intensity):
    """æ ¹æ®å¼ºåº¦å€¼è¿”å›ç­‰çº§"""
    if intensity >= 0.7:
        return "é«˜"
    elif intensity >= 0.4:  # è°ƒæ•´ä¸­ç­‰é˜ˆå€¼
        return "ä¸­ç­‰"
    else:
        return "ä½"


def get_intensity_category(intensity):
    """æ ¹æ®å¼ºåº¦å€¼è¿”å›å®‰å…¨åˆ†ç±»ï¼ˆä½/ä¸­/é«˜ï¼‰"""
    if intensity >= 0.7:  # è°ƒæ•´é˜ˆå€¼
        return "high"
    elif intensity >= 0.4:
        return "medium"
    else:
        return "low"


def check_critical_keywords(text):
    """æ£€æŸ¥ç´§æ€¥å…³é”®è¯"""
    text_lower = text.lower()
    found_keywords = []

    for keyword in CRITICAL_KEYWORDS:
        if keyword in text_lower:
            found_keywords.append(keyword)

    return found_keywords


def safety_classification(mark_a, mark_b, text):
    """
    å®‰å…¨æ£€æŸ¥åˆ†ç±»
    æ ¹æ®æƒ…ç»ªç±»å‹å’Œå¼ºåº¦ï¼Œç»“åˆå…³é”®è¯è¿›è¡Œå®‰å…¨è¯„ä¼°
    """
    primary_emotion = mark_a['primary_emotion']
    intensity_value = mark_b['intensity']

    # è·å–å¼ºåº¦åˆ†ç±»
    intensity_category = get_intensity_category(intensity_value)

    # æ ¹æ®è§„åˆ™è¡¨æ ¼è·å–åŸºç¡€å®‰å…¨ç­‰çº§
    base_safety_level = SAFETY_RULES.get(primary_emotion, {}).get(intensity_category, "normal")

    # æ£€æŸ¥ç´§æ€¥å…³é”®è¯
    critical_keywords = check_critical_keywords(text)

    # å®‰å…¨è¯„ä¼°é€»è¾‘
    safety_result = {
        'base_safety_level': base_safety_level,
        'critical_keywords_found': critical_keywords,
        'final_safety_level': base_safety_level,
        'should_interrupt': False,
        'emergency_contact': False
    }

    # å¦‚æœæœ‰ç´§æ€¥å…³é”®è¯ï¼Œå‡çº§ä¸ºcritical
    if critical_keywords:
        safety_result['final_safety_level'] = 'critical'

    # å¦‚æœæ˜¯criticalçº§åˆ«ï¼Œè®¾ç½®ä¸­æ–­æ ‡å¿—
    if safety_result['final_safety_level'] == 'critical':
        safety_result['should_interrupt'] = True
        safety_result['emergency_contact'] = True

    return safety_result


# æ¥å£å‡½æ•°
def analyze_user_text(text):
    """
    ä¸»è¦åˆ†æå‡½æ•° - å®Œæˆç¬¬1-3å±‚åˆ†æ
    å¦‚æœæ£€æµ‹åˆ°criticalæƒ…å†µï¼Œç«‹å³ä¸­æ–­å¹¶å¯åŠ¨ç´§æ€¥æµç¨‹
    """
    print(f"\nğŸ“ åˆ†æç”¨æˆ·è¾“å…¥: {text}")
    print("=" * 60)

    # 1. æƒ…æ„Ÿåˆ†ç±» (æ ‡è®°a)
    mark_a = ekman_emotion_classification(text)
    print(f"ğŸ­ æƒ…ç»ªåˆ†ç±»ç»“æœ:")
    print(f"   â†’ ä¸»è¦æƒ…ç»ª: {mark_a['primary_emotion']}")
    print(f"   â†’ ç½®ä¿¡åº¦: {mark_a['confidence']:.2f}")

    # 2. æƒ…æ„Ÿå¼ºåº¦åˆ†æ (æ ‡è®°b)
    mark_b = emotion_intensity_analysis(text)
    print(f"ğŸ“Š æƒ…æ„Ÿå¼ºåº¦åˆ†æ:")
    print(f"   â†’ å¼ºåº¦å€¼: {mark_b['intensity']:.2f}")
    print(f"   â†’ å¼ºåº¦ç­‰çº§: {mark_b['level']}")

    # 3. å…³é”®è¯æå–
    keywords = extract_keywords(text)
    print(f"ğŸ”‘ å…³é”®è¯æå–:")
    print(f"   â†’ å…³é”®è¯: {keywords}")

    # 4. å®‰å…¨æ£€æŸ¥åˆ†ç±»
    safety_result = safety_classification(mark_a, mark_b, text)
    print(f"ğŸ›¡ï¸ å®‰å…¨æ£€æŸ¥ç»“æœ:")
    print(f"   â†’ åŸºç¡€å®‰å…¨ç­‰çº§: {safety_result['base_safety_level']}")
    print(f"   â†’ æœ€ç»ˆå®‰å…¨ç­‰çº§: {safety_result['final_safety_level']}")
    print(f"   â†’ æ£€æµ‹åˆ°å…³é”®è¯: {safety_result['critical_keywords_found']}")
    print(f"   â†’ æ˜¯å¦éœ€è¦ä¸­æ–­: {'æ˜¯' if safety_result['should_interrupt'] else 'å¦'}")
    print(f"   â†’ æ˜¯å¦éœ€è¦ç´§æ€¥è”ç³»: {'æ˜¯' if safety_result['emergency_contact'] else 'å¦'}")

    # æ„å»ºå®Œæ•´åˆ†ææ•°æ®
    analysis_data = {
        "mark_a": mark_a,  # æƒ…æ„Ÿåˆ†ç±»
        "mark_b": mark_b,  # æƒ…æ„Ÿå¼ºåº¦
        "keywords": keywords,  # å…³é”®è¯
        "safety_result": safety_result,  # å®‰å…¨åˆ†ç±»
        "user_text": text  # ç”¨æˆ·åŸå§‹æ–‡æœ¬
    }

    # 5. å¦‚æœè¾¾åˆ°criticalçº§åˆ«ï¼Œè§¦å‘ç´§æ€¥åè®®å¹¶çœŸæ­£ä¸­æ–­
    if safety_result['should_interrupt']:
        print("ğŸš¨ æ£€æµ‹åˆ°ç´§æ€¥æƒ…å†µï¼Œå¯åŠ¨ç´§æ€¥åè®®...")

        # ç¬¬ä¸€æ­¥ï¼šè°ƒç”¨Hugging Faceå®‰æŠšAPI
        comfort_response = send_to_comfort_api(analysis_data, text)
        print(f"ğŸ’¬ å®‰æŠšå›å¤: {comfort_response.get('comfort_message', 'å®‰æŠšæ¶ˆæ¯å‘é€æˆåŠŸ')}")

        # ç¬¬äºŒæ­¥ï¼šè·å–å¹¶æ˜¾ç¤ºå¿ƒç†å¥åº·çƒ­çº¿
        hotlines = get_mental_health_hotlines()
        hotline_display = format_hotlines_for_display(hotlines)

        print("ğŸ“ å»ºè®®æ‹¨æ‰“çš„å¿ƒç†å¥åº·çƒ­çº¿:")
        for line in hotline_display:
            print(f"   {line}")

        print("ğŸ’¡ è¯·ç«‹å³æ‹¨æ‰“ä»¥ä¸Šçƒ­çº¿å¯»æ±‚ä¸“ä¸šå¸®åŠ©ï¼")

        # è¿”å›ä¸­æ–­å“åº”ï¼Œä¸ç»§ç»­åç»­å¤„ç†
        result = {
            "processing_complete": False,
            "emergency_triggered": True,
            "safety_level": "critical",
            "comfort_response": comfort_response,
            "recommended_hotlines": hotlines,
            "hotlines_display": hotline_display,
            "analysis_data": analysis_data,  # åŒ…å«åˆ†æç»“æœï¼Œä½†æ ‡è®°ä¸ºå·²ä¸­æ–­
            "message": "æ£€æµ‹åˆ°ç´§æ€¥æƒ…å†µï¼Œå·²æä¾›å®‰æŠšå›å¤å’Œå¿ƒç†å¥åº·çƒ­çº¿å»ºè®®ï¼Œåç»­å¤„ç†å·²ä¸­æ–­"
        }

        print("âŒ å¤„ç†å·²ä¸­æ–­ï¼Œå·²å»ºè®®ç”¨æˆ·æ‹¨æ‰“å¿ƒç†å¥åº·çƒ­çº¿")

    else:
        # æ­£å¸¸æƒ…å†µï¼Œç»§ç»­åç»­å¤„ç†
        result = {
            "processing_complete": True,
            "emergency_triggered": False,
            "safety_result": safety_result,  # å®‰å…¨åˆ†ç±»
            "mark_a": mark_a,  # æƒ…æ„Ÿåˆ†ç±»
            "mark_b": mark_b,  # æƒ…æ„Ÿå¼ºåº¦
            "keywords": keywords,  # å…³é”®è¯
            "message": "ç¬¬1-3å±‚åˆ†æå®Œæˆï¼Œå‡†å¤‡è¿›è¡Œåç»­å¤„ç†"
        }
        print("âœ… ç¬¬1-3å±‚åˆ†æå®Œæˆ")

    print("=" * 60)
    return result


def main():
    """ä¸»å‡½æ•°ï¼šå…è®¸ç”¨æˆ·è¾“å…¥è‡ªå·±çš„è¯­å¥"""
    print("ğŸ­ æƒ…æ„Ÿåˆ†æç³»ç»Ÿå¯åŠ¨")
    print("=" * 50)

    # è®¾ç½®åœ°ç‚¹ï¼ˆåœ¨ä»£ç ä¸­è®¾ç½®ï¼‰
    set_current_province(CURRENT_PROVINCE)
    print(f"ğŸ“ å½“å‰åœ°ç‚¹: {CURRENT_PROVINCE}")

    print("\nğŸ’¬ è¯·è¾“å…¥æ‚¨æƒ³è¦åˆ†æçš„è¯­å¥ï¼ˆè¾“å…¥'é€€å‡º'æˆ–'quit'ç»“æŸç¨‹åºï¼‰:")
    print("-" * 50)

    while True:
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = input("\nè¯·è¾“å…¥è¯­å¥: ").strip()

        # æ£€æŸ¥é€€å‡ºæ¡ä»¶
        if user_input.lower() in ['é€€å‡º', 'quit', 'exit']:
            print("æ„Ÿè°¢ä½¿ç”¨æƒ…æ„Ÿåˆ†æç³»ç»Ÿï¼Œå†è§ï¼")
            break

        # æ£€æŸ¥ç©ºè¾“å…¥
        if not user_input:
            print("âš ï¸  è¾“å…¥ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
            continue

        print("\n" + "=" * 60)
        print("å¼€å§‹åˆ†æ...")

        try:
            # è°ƒç”¨åˆ†æå‡½æ•°
            result = analyze_user_text(user_input)

            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            print("\nğŸ“‹ åˆ†æç»“æœæ‘˜è¦:")
            print(f"   æƒ…ç»ª: {result.get('mark_a', {}).get('primary_emotion', 'æœªçŸ¥')}")
            print(
                f"   å¼ºåº¦: {result.get('mark_b', {}).get('intensity', 0):.2f} ({result.get('mark_b', {}).get('level', 'æœªçŸ¥')})")
            print(f"   å®‰å…¨ç­‰çº§: {result.get('safety_result', {}).get('final_safety_level', 'æœªçŸ¥')}")

            if result.get('emergency_triggered'):
                print("   ğŸš¨ å·²è§¦å‘ç´§æ€¥åè®®ï¼Œè¯·ç«‹å³å¯»æ±‚ä¸“ä¸šå¸®åŠ©ï¼")

        except Exception as e:
            print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            print("è¯·ç¨åé‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚")

        print("=" * 60)
        print("\næ‚¨å¯ä»¥ç»§ç»­è¾“å…¥å…¶ä»–è¯­å¥è¿›è¡Œåˆ†æï¼Œæˆ–è¾“å…¥'é€€å‡º'ç»“æŸç¨‹åºã€‚")
        return result


def api():
    print("\nğŸ’¬ è¯·è¾“å…¥æ‚¨æƒ³è¦åˆ†æçš„è¯­å¥ï¼ˆè¾“å…¥'é€€å‡º'æˆ–'quit'ç»“æŸç¨‹åºï¼‰:")
    print("-" * 50)
    # è·å–ç”¨æˆ·è¾“å…¥
    user_input = input("\nè¯·è¾“å…¥è¯­å¥: ").strip()

    # æ£€æŸ¥é€€å‡ºæ¡ä»¶
    if user_input.lower() in ['é€€å‡º', 'quit', 'exit']:
        print("æ„Ÿè°¢ä½¿ç”¨æƒ…æ„Ÿåˆ†æç³»ç»Ÿï¼Œå†è§ï¼")
        return result

    # æ£€æŸ¥ç©ºè¾“å…¥
    if not user_input:
        print("âš ï¸  è¾“å…¥ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
        return result

    print("\n" + "=" * 60)
    print("å¼€å§‹åˆ†æ...")

    try:
        # è°ƒç”¨åˆ†æå‡½æ•°
        result = analyze_user_text(user_input)

        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        print("\nğŸ“‹ åˆ†æç»“æœæ‘˜è¦:")
        print(f"   æƒ…ç»ª: {result.get('mark_a', {}).get('primary_emotion', 'æœªçŸ¥')}")
        print(
            f"   å¼ºåº¦: {result.get('mark_b', {}).get('intensity', 0):.2f} ({result.get('mark_b', {}).get('level', 'æœªçŸ¥')})")
        print(f"   å®‰å…¨ç­‰çº§: {result.get('safety_result', {}).get('final_safety_level', 'æœªçŸ¥')}")

        if result.get('emergency_triggered'):
            print("   ğŸš¨ å·²è§¦å‘ç´§æ€¥åè®®ï¼Œè¯·ç«‹å³å¯»æ±‚ä¸“ä¸šå¸®åŠ©ï¼")

    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯·ç¨åé‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚")

    print("=" * 60)
    print("\næ‚¨å¯ä»¥ç»§ç»­è¾“å…¥å…¶ä»–è¯­å¥è¿›è¡Œåˆ†æï¼Œæˆ–è¾“å…¥'é€€å‡º'ç»“æŸç¨‹åºã€‚")
    return result


# æµ‹è¯•ç¤ºä¾‹
if __name__ == '__main__':
    # ç›´æ¥è¿è¡Œä¸»å‡½æ•°ï¼Œè®©ç”¨æˆ·è¾“å…¥è¯­å¥
    main()

